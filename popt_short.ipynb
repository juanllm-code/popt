{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "PzSygUHa5z_E",
        "yJKo4pwvtd7e",
        "m6ZZ2f7SvMaP"
      ],
      "authorship_tag": "ABX9TyOWDYYa/PRqTTycjhrg1oUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f70c1b7139fa4bb694b5dddcf5751450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a141aa206fb54be6b034f8050c5343f1",
              "IPY_MODEL_e0717c89f1934b76ae90819ef3588737",
              "IPY_MODEL_e9213546e4d54958ba6de5fe207c81d9"
            ],
            "layout": "IPY_MODEL_318fc2e3d6454699abd4efe2af639a3a"
          }
        },
        "a141aa206fb54be6b034f8050c5343f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be3ba5afe54437ebccf7aa298a34067",
            "placeholder": "​",
            "style": "IPY_MODEL_f9fd4c63efcd4f969928a2753b38bae2",
            "value": "Extracting prompt in train dataset: 100%"
          }
        },
        "e0717c89f1934b76ae90819ef3588737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25717894809849c6895c1de0e08af4b2",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_192b1741837042f9afcdb3ea69249527",
            "value": 500
          }
        },
        "e9213546e4d54958ba6de5fe207c81d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3807889dd9f483daebc0b58e40d9052",
            "placeholder": "​",
            "style": "IPY_MODEL_3a63a1d46cea40ee96253e45ea81d06c",
            "value": " 500/500 [00:00&lt;00:00, 2705.09 examples/s]"
          }
        },
        "318fc2e3d6454699abd4efe2af639a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be3ba5afe54437ebccf7aa298a34067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fd4c63efcd4f969928a2753b38bae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25717894809849c6895c1de0e08af4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192b1741837042f9afcdb3ea69249527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3807889dd9f483daebc0b58e40d9052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a63a1d46cea40ee96253e45ea81d06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b6d10894454556911af3e7b8aaaf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9a2f61cd6554430ab436104f1dd2d83",
              "IPY_MODEL_0ce32de1a477420d8184e546bd9716b8",
              "IPY_MODEL_676b08f639a04bc3af734abe68b44a87"
            ],
            "layout": "IPY_MODEL_9e7a9bf0a6f248ccbec611c74d094c7e"
          }
        },
        "e9a2f61cd6554430ab436104f1dd2d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1566572aa44705a2a09e5181d07a9d",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c7412ddca54c68ad26c2ec4e3b9a6e",
            "value": "Applying chat template to train dataset: 100%"
          }
        },
        "0ce32de1a477420d8184e546bd9716b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a41f4465ea14f088765ba86c3ac29fb",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0959a31f69de41f3871355eb9f153a78",
            "value": 500
          }
        },
        "676b08f639a04bc3af734abe68b44a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74062ed8fc47434bbff6cf68905052b7",
            "placeholder": "​",
            "style": "IPY_MODEL_06b16d8fd93a488fa7b9ee0277173ccd",
            "value": " 500/500 [00:00&lt;00:00, 2166.85 examples/s]"
          }
        },
        "9e7a9bf0a6f248ccbec611c74d094c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1566572aa44705a2a09e5181d07a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c7412ddca54c68ad26c2ec4e3b9a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a41f4465ea14f088765ba86c3ac29fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0959a31f69de41f3871355eb9f153a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74062ed8fc47434bbff6cf68905052b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b16d8fd93a488fa7b9ee0277173ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e47dc89e4f144c49be5701801fd65dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccf17684bdd242348a65f9a63362d585",
              "IPY_MODEL_4d99ba939d204ba3890b49800fe98714",
              "IPY_MODEL_fa35b6a385664ee38967a1e2e2025a95"
            ],
            "layout": "IPY_MODEL_f4ce1a66fda34f11b73a962f87aef4e7"
          }
        },
        "ccf17684bdd242348a65f9a63362d585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917273195f1d4c0b9e161efa371a7eea",
            "placeholder": "​",
            "style": "IPY_MODEL_6e980bd2a6964e958f9ae9fd624ddd2e",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "4d99ba939d204ba3890b49800fe98714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb197d80aff424bacdbf6abcb0b8dd5",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dcbd3b2bfaa4fe1b0379eae8e711b13",
            "value": 500
          }
        },
        "fa35b6a385664ee38967a1e2e2025a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbc4431983074c4ebd7fba250becde28",
            "placeholder": "​",
            "style": "IPY_MODEL_56db3668b27343ba90caab63d1b5dffd",
            "value": " 500/500 [00:01&lt;00:00, 319.54 examples/s]"
          }
        },
        "f4ce1a66fda34f11b73a962f87aef4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917273195f1d4c0b9e161efa371a7eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e980bd2a6964e958f9ae9fd624ddd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbb197d80aff424bacdbf6abcb0b8dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcbd3b2bfaa4fe1b0379eae8e711b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbc4431983074c4ebd7fba250becde28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56db3668b27343ba90caab63d1b5dffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanllm-code/popt/blob/main/popt_short.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "\n",
        "In this colab, we benchmark [POPT](https://medium.com/@juan.sunnyvale/popt-why-preference-optimization-works-and-why-it-wont-take-over-the-world-d550b1cacad7) and [DPO](https://arxiv.org/abs/2305.18290) for fine-tuning LLMs. To run this colab, you will need to connect to a high-RAM A100 GPU.\n",
        "\n",
        "In this colab, due to compute constraints, we fine-tune with 500 samples taken from the trl-lib/ultrafeedback_binarized dataset. The dataset lends itself to work with DPO, but with some minor data-prep, we make it work for POPT."
      ],
      "metadata": {
        "id": "7_-q9R1edFg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Dependencies and Verify you have GPUs\n",
        "\n",
        "The first cell may take a couple of mins to run. You may be prompted to restart the colab, and if so, please restart. One of the libraries contains the functions that we will use to score DPO and POPT predictions, and the other library (trl) contains the implementation of DPO. It is pinned to a specific version because trl changes very rapidly, and hence this code may not work for past versions.\n",
        "\n",
        "The second cell runs nvidia-smi to read available GPUs. If you do not have at least one A100 available, this code may not run."
      ],
      "metadata": {
        "id": "ay_tjWtdfYDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl==0.15.2 rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MHnXIyliorGi",
        "outputId": "5e638a3d-b485-4cb5-ca39-9c753d444738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trl\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.3.0)\n",
            "Collecting datasets>=2.21.0 (from trl)\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.48.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.21.0->trl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
            "Collecting xxhash (from datasets>=2.21.0->trl)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.21.0->trl)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.11.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate>=0.34.0->trl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=4ebb47c4283d9a6e6598f121faf00b928200525fb5251f2e1328cf893176b13f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, trl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed datasets-3.4.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rouge-score-0.1.2 trl-0.15.2 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg9DMwPQokSE",
        "outputId": "36ebcf5a-d684-4013-8b28-8c6b255d31cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 14 03:11:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0             37W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POPT Trainer Implementation\n",
        "\n",
        "Here we define a simple POPT trainer. The most important part and contribution here is the loss function, which follows the formula proposed and proven [here](https://medium.com/@juan.sunnyvale/popt-the-preference-optimized-policy-theorem-b0ab20970518)"
      ],
      "metadata": {
        "id": "HWb1SOoQrgo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import os\n",
        "import logging\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "from datetime import datetime\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "class POPTTrainer(Trainer):\n",
        "    \"\"\"Preference-Optimized Policy Trainer (POPT) implementation\"\"\"\n",
        "\n",
        "    def __init__(self, model, ref_model, beta=1.0, *args, **kwargs):\n",
        "        super().__init__(model, *args, **kwargs)\n",
        "        self.ref_model = ref_model\n",
        "        self.beta = beta\n",
        "        self.metrics_history = {'loss': [], 'kl_div': [], 'reward': []}\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "      \"\"\"Custom loss function for POPT\"\"\"\n",
        "      # Move inputs to device if needed\n",
        "      inputs = {k: v.to(model.device) if hasattr(v, 'to') else v for k, v in inputs.items()}\n",
        "\n",
        "      # Get model outputs\n",
        "      outputs = model(**inputs)\n",
        "      logits = outputs.logits\n",
        "\n",
        "      # Get reference model outputs\n",
        "      with torch.no_grad():\n",
        "          ref_outputs = self.ref_model(**inputs)\n",
        "          ref_logits = ref_outputs.logits\n",
        "\n",
        "      # Compute KL divergence (normalized)\n",
        "      log_probs = F.log_softmax(logits, dim=-1)\n",
        "      ref_log_probs = F.log_softmax(ref_logits, dim=-1)\n",
        "\n",
        "      kl_div = ((log_probs - ref_log_probs).sum(dim=-1).mean()) / log_probs.shape[-1]\n",
        "\n",
        "      # Compute reward (use mean instead of sum)\n",
        "      reward = log_probs.mean()\n",
        "\n",
        "      # Final loss (increase beta)\n",
        "      loss = -reward + self.beta * kl_div\n",
        "      print(f\"KL={kl_div}, Reward={reward}, Loss={loss}\")\n",
        "\n",
        "      # Store metrics for evaluation\n",
        "      if not getattr(self, \"is_in_train\", True):\n",
        "          with torch.no_grad():\n",
        "              self.metrics_history['loss'].append(float(loss.item()))\n",
        "              self.metrics_history['kl_div'].append(float(kl_div.item()))\n",
        "              self.metrics_history['reward'].append(float(reward.item()))\n",
        "\n",
        "      return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "O8KGAgqEgvr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading\n",
        "\n",
        "Nothing fancy. Just downloading the data. It will take a couple of mins"
      ],
      "metadata": {
        "id": "hZRVgEjsiIRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== DATA LOADING =====\n",
        "def prepare_datasets(tokenizer):\n",
        "    \"\"\"Load and prepare dataset\"\"\"\n",
        "    logger.info(f\"Loading dataset: {CONFIG['dataset_name']}\")\n",
        "    dataset = load_dataset(CONFIG[\"dataset_name\"], split=CONFIG[\"dataset_split\"])\n",
        "\n",
        "    # ✅ Limit training set to 500 samples\n",
        "    train_data = dataset.select(range(CONFIG[\"num_train_samples\"]))\n",
        "\n",
        "    # ✅ Select separate evaluation samples\n",
        "    eval_data = dataset.select(range(CONFIG[\"num_train_samples\"], CONFIG[\"num_train_samples\"] + CONFIG[\"eval_samples\"]))\n",
        "\n",
        "    logger.info(f\"Training samples: {len(train_data)}\")\n",
        "    logger.info(f\"Evaluation samples: {len(eval_data)}\")\n",
        "\n",
        "    return train_data, eval_data"
      ],
      "metadata": {
        "id": "zFkzYmLQiGcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training functions\n",
        "\n",
        "Here we define the functions to fine tune using DPO and POPT. Some things for people to play around with if hardware allows are:\n",
        "\n",
        "- Batch size: Keeping it pretty low per GPU (1 or 2) to avoid OOMs\n",
        "- Gradient accumulation (the higher the batch size, the less you need to think about this).\n",
        "- max_prompt_length: We could go for the full prompts, although we are restricting it here\n",
        "\n",
        "For DPO, the data from the dataset is essentially \"plug-and-play\", so most of what we do is set up configs here. However, the train_popt function is a bit more involved because it requires putting the data in a pytorch dataset."
      ],
      "metadata": {
        "id": "5hNnpYjViery"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== TRAINING FUNCTIONS =====\n",
        "def train_dpo(tokenizer, train_data, eval_data):\n",
        "    \"\"\"Train a model using DPO and evaluate after training.\"\"\"\n",
        "    logger.info(\"Starting DPO training\")\n",
        "\n",
        "    try:\n",
        "        # ✅ Free GPU memory before training\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        # ✅ Load model with gradient checkpointing\n",
        "        model = AutoModelForCausalLM.from_pretrained(CONFIG[\"model_name\"]).to(device)\n",
        "        model.gradient_checkpointing_enable()  # ✅ Enable memory-efficient training\n",
        "\n",
        "        # ✅ Reduce batch size to 1 for lower memory usage\n",
        "        dpo_config = DPOConfig(\n",
        "            output_dir=os.path.join(CONFIG[\"output_dir\"], \"dpo\"),\n",
        "            per_device_train_batch_size=2,  # ✅ Small batch size\n",
        "            gradient_accumulation_steps=4,  # ✅ Accumulate gradients to compensate\n",
        "            learning_rate=CONFIG[\"learning_rate\"],\n",
        "            num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
        "            beta=CONFIG[\"beta\"],\n",
        "            logging_steps=10,\n",
        "            save_strategy=\"no\",\n",
        "            evaluation_strategy=\"no\",\n",
        "            max_prompt_length=CONFIG[\"max_length\"] // 2,\n",
        "            padding_value=tokenizer.pad_token_id,\n",
        "            fp16=True,  # ✅ Mixed precision for H100\n",
        "        )\n",
        "\n",
        "        # ✅ Train with DPOTrainer\n",
        "        dpo_trainer = DPOTrainer(\n",
        "            model=model,\n",
        "            args=dpo_config,\n",
        "            train_dataset=train_data,\n",
        "            tokenizer=tokenizer,\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "        dpo_trainer.train()\n",
        "        training_time = time.time() - start_time\n",
        "        logger.info(f\"DPO training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        # ✅ Evaluate model after training\n",
        "        metrics, samples = evaluate_model(model, tokenizer, eval_data, \"DPO\")\n",
        "        metrics[\"training_time\"] = training_time\n",
        "\n",
        "        # ✅ Save results\n",
        "        results = {\n",
        "            \"method\": \"DPO\",\n",
        "            \"evaluation_metrics\": metrics,\n",
        "            \"samples\": samples,\n",
        "            \"training_time\": training_time,\n",
        "            \"model_size\": sum(p.numel() for p in model.parameters()),\n",
        "            \"parameters\": {\n",
        "                \"beta\": CONFIG[\"beta\"],\n",
        "                \"learning_rate\": CONFIG[\"learning_rate\"],\n",
        "                \"batch_size\": 1,  # ✅ Use batch_size=1\n",
        "                \"epochs\": CONFIG[\"num_train_epochs\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(CONFIG[\"output_dir\"], \"dpo_results.json\"), \"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        return model, metrics, results\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in DPO training: {e}\")\n",
        "        logger.exception(\"Details:\")\n",
        "        results = {\n",
        "            \"method\": \"DPO\",\n",
        "            \"error\": str(e),\n",
        "            \"training_time\": 0.0,\n",
        "            \"evaluation_metrics\": {\n",
        "                \"rouge1\": 0.0,\n",
        "                \"rouge2\": 0.0,\n",
        "                \"rougeL\": 0.0\n",
        "            }\n",
        "        }\n",
        "        return None, None, results\n",
        "\n",
        "def train_popt(tokenizer, train_data, eval_data):\n",
        "    \"\"\"Train a model using POPT method\"\"\"\n",
        "    logger.info(\"Starting POPT training\")\n",
        "\n",
        "    try:\n",
        "        # ✅ Free GPU memory before training\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        # ✅ Load models\n",
        "        model = AutoModelForCausalLM.from_pretrained(CONFIG[\"model_name\"]).to(device)\n",
        "        ref_model = AutoModelForCausalLM.from_pretrained(CONFIG[\"model_name\"]).to(device)\n",
        "\n",
        "        # ✅ Enable memory optimization\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "        # ✅ Convert `train_data` into a dataset (since we removed `train_dataset`)\n",
        "        class PreferenceDataset(torch.utils.data.Dataset):\n",
        "            def __init__(self, data, tokenizer):\n",
        "                self.data = data\n",
        "                self.tokenizer = tokenizer\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.data)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                item = self.data[idx]\n",
        "                user_input = next(msg[\"content\"] for msg in item[\"chosen\"] if msg[\"role\"] == \"user\")\n",
        "                chosen_output = next(msg[\"content\"] for msg in item[\"chosen\"] if msg[\"role\"] == \"assistant\")\n",
        "\n",
        "                tokens = self.tokenizer(\n",
        "                    user_input,\n",
        "                    max_length=CONFIG[\"max_length\"],\n",
        "                    padding=\"max_length\",\n",
        "                    truncation=True,\n",
        "                    return_tensors=\"pt\",\n",
        "                )\n",
        "\n",
        "                return {\n",
        "                    \"input_ids\": tokens[\"input_ids\"][0],\n",
        "                    \"attention_mask\": tokens[\"attention_mask\"][0],\n",
        "                    \"labels\": self.tokenizer(\n",
        "                        chosen_output,\n",
        "                        max_length=CONFIG[\"max_length\"],\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        return_tensors=\"pt\",\n",
        "                    )[\"input_ids\"][0],\n",
        "                }\n",
        "\n",
        "        # ✅ Convert train_data into a PyTorch dataset\n",
        "        train_dataset = PreferenceDataset(train_data, tokenizer)\n",
        "\n",
        "        # ✅ Set up training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=os.path.join(CONFIG[\"output_dir\"], \"popt\"),\n",
        "            per_device_train_batch_size=2,  # ✅ Small batch size to prevent OOM\n",
        "            gradient_accumulation_steps=4,  # ✅ Stabilizes training\n",
        "            learning_rate=CONFIG[\"learning_rate\"],\n",
        "            num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
        "            logging_dir=os.path.join(CONFIG[\"output_dir\"], \"popt_logs\"),\n",
        "            logging_steps=10,\n",
        "            save_strategy=\"epoch\",\n",
        "            save_total_limit=1,\n",
        "            evaluation_strategy=\"no\",\n",
        "            fp16=True,  # ✅ Mixed precision for memory efficiency\n",
        "            max_grad_norm=1.0,\n",
        "            weight_decay=0.01,\n",
        "            remove_unused_columns=False,\n",
        "        )\n",
        "\n",
        "        # ✅ Create POPT trainer\n",
        "        trainer = POPTTrainer(\n",
        "            model=model,\n",
        "            ref_model=ref_model,\n",
        "            beta=CONFIG[\"beta\"],\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "        )\n",
        "\n",
        "        # ✅ Train model and measure time\n",
        "        start_time = time.time()\n",
        "        trainer.train()\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        logger.info(f\"POPT training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        # ✅ Save the model\n",
        "        model_save_path = os.path.join(CONFIG[\"output_dir\"], \"popt_model\")\n",
        "        model.save_pretrained(model_save_path)\n",
        "        tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "        # ✅ Evaluate the model (limit eval to 100 samples)\n",
        "        metrics, samples = evaluate_model(model, tokenizer, eval_data, \"POPT\", max_eval_samples=100)\n",
        "        metrics[\"training_time\"] = training_time\n",
        "\n",
        "        # ✅ Save results\n",
        "        results = {\n",
        "            \"method\": \"POPT\",\n",
        "            \"training_metrics\": {\n",
        "                \"loss\": trainer.metrics_history.get('loss', []),\n",
        "                \"kl_div\": trainer.metrics_history.get('kl_div', []),\n",
        "                \"reward\": trainer.metrics_history.get('reward', [])\n",
        "            },\n",
        "            \"evaluation_metrics\": metrics,\n",
        "            \"samples\": samples,\n",
        "            \"training_time\": training_time,\n",
        "            \"model_size\": sum(p.numel() for p in model.parameters()),\n",
        "            \"parameters\": {\n",
        "                \"beta\": CONFIG[\"beta\"],\n",
        "                \"learning_rate\": CONFIG[\"learning_rate\"],\n",
        "                \"batch_size\": 2,  # ✅ Small batch size\n",
        "                \"epochs\": CONFIG[\"num_train_epochs\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(CONFIG[\"output_dir\"], \"popt_results.json\"), \"w\") as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        # ✅ Print Training Time\n",
        "        print(\"\\n=== POPT Training Time ===\")\n",
        "        print(f\"{training_time:.2f} seconds\\n\")\n",
        "\n",
        "        # ✅ Print Evaluation Metrics\n",
        "        print(\"\\n=== POPT Evaluation Metrics ===\")\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "        # ✅ Print Generated Samples\n",
        "        print(\"\\n=== Sample Generated Outputs (POPT) ===\")\n",
        "        for i, sample in enumerate(samples[:5]):  # Print only first 5 samples\n",
        "            print(f\"\\nSample {i+1}:\")\n",
        "            print(f\"Prompt: {sample['prompt']}\")\n",
        "            print(f\"Reference: {sample['reference']}\")\n",
        "            print(f\"Model Output: {sample['generation']}\")\n",
        "\n",
        "        return model, metrics, results\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in POPT training: {e}\")\n",
        "        logger.exception(\"Details:\")\n",
        "\n",
        "        # ✅ Create error results\n",
        "        results = {\n",
        "            \"method\": \"POPT\",\n",
        "            \"error\": str(e),\n",
        "            \"training_time\": 0.0,\n",
        "            \"evaluation_metrics\": {\n",
        "                \"rouge1\": 0.0,\n",
        "                \"rouge2\": 0.0,\n",
        "                \"rougeL\": 0.0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return None, None, results"
      ],
      "metadata": {
        "id": "RTqkyfx7INC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "For evaluation, we are computing ROUGE scores, which tell us how close the text generated by the fine-tuned models is to the text created by humans.\n",
        "\n",
        "We also keep track of training time, generation time, and tokens per second"
      ],
      "metadata": {
        "id": "DQQKZuSwkf8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== EVALUATION =======\n",
        "\n",
        "def compute_rouge_metrics(predictions, references, tokenizer):\n",
        "    \"\"\"Compute ROUGE metrics for generated text\"\"\"\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "    scores = {\n",
        "        'rouge1': [],\n",
        "        'rouge2': [],\n",
        "        'rougeL': []\n",
        "    }\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        results = scorer.score(ref, pred)\n",
        "        scores['rouge1'].append(results['rouge1'].fmeasure)\n",
        "        scores['rouge2'].append(results['rouge2'].fmeasure)\n",
        "        scores['rougeL'].append(results['rougeL'].fmeasure)\n",
        "\n",
        "    # Calculate averages\n",
        "    metrics = {\n",
        "        'rouge1': np.mean(scores['rouge1']),\n",
        "        'rouge2': np.mean(scores['rouge2']),\n",
        "        'rougeL': np.mean(scores['rougeL'])\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_model(model, tokenizer, eval_data, method_name, max_eval_samples=100):\n",
        "    \"\"\"Evaluate a model on a subset of preference data (max 100 samples)\"\"\"\n",
        "    logger.info(f\"Evaluating {method_name} model\")\n",
        "    model.eval()\n",
        "\n",
        "    try:\n",
        "        # ✅ Select up to 100 evaluation samples\n",
        "        num_samples = min(max_eval_samples, len(eval_data))\n",
        "        eval_samples = eval_data.select(range(num_samples))  # ✅ Use .select() instead of slicing\n",
        "\n",
        "        # ✅ Convert dataset to a list of dictionaries if necessary\n",
        "        if isinstance(eval_samples, Dataset):\n",
        "            eval_samples = eval_samples.to_list()\n",
        "\n",
        "        # ✅ Debugging print to check structure\n",
        "        print(f\"Eval Samples Type: {type(eval_samples)}\")\n",
        "        print(f\"First Sample: {eval_samples[0]}\") if eval_samples else print(\"No samples available.\")\n",
        "\n",
        "        # ✅ Extract prompts correctly\n",
        "        prompts = []\n",
        "        references = []\n",
        "\n",
        "        for item in eval_samples:\n",
        "            try:\n",
        "                # ✅ Extract the first message from \"chosen\" that has role \"user\"\n",
        "                user_message = next(msg[\"content\"] for msg in item[\"chosen\"] if msg[\"role\"] == \"user\")\n",
        "                assistant_response = next(msg[\"content\"] for msg in item[\"chosen\"] if msg[\"role\"] == \"assistant\")\n",
        "\n",
        "                prompts.append(user_message)\n",
        "                references.append(assistant_response)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Skipping a sample due to missing keys: {e}\")\n",
        "                continue  # Skip this sample if it's malformed\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing evaluation dataset: {e}\")\n",
        "        return {}, []  # ✅ FIXED: Return empty metrics and samples instead of None\n",
        "\n",
        "    # Set up generation pipeline\n",
        "    gen_pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=0 if torch.cuda.is_available() else -1,\n",
        "    )\n",
        "\n",
        "    # Generate responses and measure time\n",
        "    start_time = time.time()\n",
        "    generations = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        try:\n",
        "            # Tokenize with attention mask\n",
        "            inputs = tokenizer(\n",
        "                prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                return_attention_mask=True\n",
        "            ).to(device)\n",
        "\n",
        "            # Generate text\n",
        "            output = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                num_return_sequences=1\n",
        "            )\n",
        "\n",
        "            # Decode generated text\n",
        "            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the newly generated part\n",
        "            if generated_text.startswith(prompt):\n",
        "                generated_text = generated_text[len(prompt):].strip()\n",
        "\n",
        "            generations.append(generated_text)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating response: {e}\")\n",
        "            generations.append(\"\")\n",
        "\n",
        "    generation_time = time.time() - start_time\n",
        "\n",
        "    # Compute metrics\n",
        "    metrics = compute_rouge_metrics(generations, references, tokenizer)\n",
        "    metrics[\"generation_time\"] = generation_time\n",
        "    metrics[\"tokens_per_second\"] = sum(len(gen.split()) for gen in generations) / generation_time\n",
        "\n",
        "    # Log results\n",
        "    logger.info(f\"=== {method_name} Evaluation Results ===\")\n",
        "    for k, v in metrics.items():\n",
        "        logger.info(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    # Save generated samples\n",
        "    samples = []\n",
        "    for i in range(min(5, len(generations))):\n",
        "        samples.append({\n",
        "            \"prompt\": prompts[i],\n",
        "            \"generation\": generations[i],\n",
        "            \"reference\": references[i]\n",
        "        })\n",
        "\n",
        "    return metrics, samples"
      ],
      "metadata": {
        "id": "pa16SrZwki55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function"
      ],
      "metadata": {
        "id": "g_M_lsAwlUBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== MAIN FUNCTION =====\n",
        "def run_benchmark():\n",
        "    \"\"\"Run DPO training benchmark\"\"\"\n",
        "    logger.info(f\"Starting preference learning benchmark at {datetime.now()}\")\n",
        "    logger.info(f\"Using model: {CONFIG['model_name']}\")\n",
        "    logger.info(f\"Using dataset: {CONFIG['dataset_name']}\")\n",
        "\n",
        "    try:\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"model_name\"])\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        # Prepare datasets\n",
        "        train_data, eval_data = prepare_datasets(tokenizer)\n",
        "\n",
        "        # Run DPO training\n",
        "        logger.info(\"\\n=== Running DPO Benchmark ===\")\n",
        "        model, metrics, results = train_dpo(tokenizer, train_data, eval_data)\n",
        "\n",
        "        # ✅ Print training time\n",
        "        print(\"\\n=== Training Time ===\")\n",
        "        print(f\"{results['training_time']:.2f} seconds\\n\")\n",
        "\n",
        "        # ✅ Print Evaluation Metrics (ROUGE Scores)\n",
        "        print(\"\\n=== Evaluation Metrics ===\")\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "        # Clean up GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        logger.info(\"\\n=== Running POPT Benchmark ===\")\n",
        "        model, metrics, results = train_popt(tokenizer, train_data, eval_data)\n",
        "\n",
        "        # ✅ Print training time\n",
        "        print(\"\\n=== Training Time ===\")\n",
        "        print(f\"{results['training_time']:.2f} seconds\\n\")\n",
        "\n",
        "        # ✅ Print Evaluation Metrics (ROUGE Scores)\n",
        "        print(\"\\n=== Evaluation Metrics ===\")\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "        # Clean up GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        logger.info(f\"Benchmark completed at {datetime.now()}\")\n",
        "        logger.info(f\"Results saved to {CONFIG['output_dir']}\")\n",
        "        return metrics, results\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in benchmark: {e}\")\n",
        "        logger.exception(\"Details:\")"
      ],
      "metadata": {
        "id": "3L6yV-aslXAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run benchmark\n",
        "\n",
        "In lines 10-22, there is a big config that the other functions use. The number of epochs could be increased, the dataset could be changed, the model name could be changed, etc."
      ],
      "metadata": {
        "id": "BMOvkTo-lkd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "    handlers=[logging.StreamHandler()],\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    \"model_name\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
        "    \"dataset_name\": \"trl-lib/ultrafeedback_binarized\",  # ✅ Use ultrafeedback_binarized\n",
        "    \"dataset_split\": \"train\",  # ✅ Use full training set, but filter later\n",
        "    \"num_train_samples\": 500,  # ✅ Train on only 500 samples\n",
        "    \"eval_samples\": 50,  # ✅ Evaluation set (optional)\n",
        "    \"output_dir\": \"./benchmark_results\",\n",
        "    \"max_length\": 256,\n",
        "    \"batch_size\": 4,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"beta\": 1.0,  # KL regularization strength\n",
        "}\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "metrics, results = run_benchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f70c1b7139fa4bb694b5dddcf5751450",
            "a141aa206fb54be6b034f8050c5343f1",
            "e0717c89f1934b76ae90819ef3588737",
            "e9213546e4d54958ba6de5fe207c81d9",
            "318fc2e3d6454699abd4efe2af639a3a",
            "1be3ba5afe54437ebccf7aa298a34067",
            "f9fd4c63efcd4f969928a2753b38bae2",
            "25717894809849c6895c1de0e08af4b2",
            "192b1741837042f9afcdb3ea69249527",
            "b3807889dd9f483daebc0b58e40d9052",
            "3a63a1d46cea40ee96253e45ea81d06c",
            "88b6d10894454556911af3e7b8aaaf6d",
            "e9a2f61cd6554430ab436104f1dd2d83",
            "0ce32de1a477420d8184e546bd9716b8",
            "676b08f639a04bc3af734abe68b44a87",
            "9e7a9bf0a6f248ccbec611c74d094c7e",
            "3e1566572aa44705a2a09e5181d07a9d",
            "b2c7412ddca54c68ad26c2ec4e3b9a6e",
            "5a41f4465ea14f088765ba86c3ac29fb",
            "0959a31f69de41f3871355eb9f153a78",
            "74062ed8fc47434bbff6cf68905052b7",
            "06b16d8fd93a488fa7b9ee0277173ccd",
            "e47dc89e4f144c49be5701801fd65dac",
            "ccf17684bdd242348a65f9a63362d585",
            "4d99ba939d204ba3890b49800fe98714",
            "fa35b6a385664ee38967a1e2e2025a95",
            "f4ce1a66fda34f11b73a962f87aef4e7",
            "917273195f1d4c0b9e161efa371a7eea",
            "6e980bd2a6964e958f9ae9fd624ddd2e",
            "cbb197d80aff424bacdbf6abcb0b8dd5",
            "2dcbd3b2bfaa4fe1b0379eae8e711b13",
            "fbc4431983074c4ebd7fba250becde28",
            "56db3668b27343ba90caab63d1b5dffd"
          ]
        },
        "id": "OfRkSntEBvsD",
        "outputId": "236df88c-9d94-4bb5-a0c7-eba5dfe07190"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-28-155ec0a12443>:212: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `DPOTrainer.__init__`. Use `processing_class` instead.\n",
            "  dpo_trainer = DPOTrainer(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f70c1b7139fa4bb694b5dddcf5751450",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting prompt in train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88b6d10894454556911af3e7b8aaaf6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e47dc89e4f144c49be5701801fd65dac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='62' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [62/62 01:05, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>10.819300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>50.502800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>50.072800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>70.459900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>65.751200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>40.054000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Samples Type: <class 'list'>\n",
            "First Sample: {'chosen': [{'content': 'Create a comprehensive social media plan that outlines the objectives, target audience, platforms, messaging, content strategy, tone of voice, frequency of posts, and metrics for measuring success for a new initiative. The plan should also include a timeline for implementation and a budget allocation for paid social media advertising.', 'role': 'user'}, {'content': 'Title: Comprehensive Social Media Plan for a New Initiative\\n\\nI. Objectives:\\n   A. Increase brand awareness and visibility\\n   B. Generate a loyal and engaged community\\n   C. Drive traffic to the website\\n   D. Generate leads and sales\\n   E. Establish ourselves as thought leaders in the industry\\n\\nII. Target Audience:\\n   A. Demographics\\n      1. Age group: 24-45\\n      2. Gender: Male and female\\n      3. Location: United States\\n      4. Occupation: Professionals and entrepreneurs\\n   B. Psychographics\\n      1. Interests: Technology, innovation, self-improvement, business growth\\n      2. Values: Success, progress, creativity, collaboration\\n\\nIII. Platforms:\\n   A. Facebook\\n   B. Instagram\\n   C. Twitter\\n   D. LinkedIn\\n   E. YouTube\\n   F. Pinterest (optional, depending on the content and industry)\\n\\nIV. Messaging:\\n   A. Key messages\\n      1. Our product/service helps you achieve success\\n      2. Join a community of like-minded individuals\\n      3. Stay ahead of the curve with the latest industry news and insights\\n   B. Tone of voice: Informative, engaging, and inspirational\\n\\nV. Content Strategy:\\n   A. Content pillars\\n      1. Educational (e.g., how-to guides, industry trends)\\n      2. Engaging (e.g., interactive polls, user-generated content)\\n      3. Promotional (e.g., product updates, discounts, sales)\\n   B. Content formats\\n      1. Visual: Images, infographics, videos\\n      2. Written: Blog articles, social media posts, interviews, case studies\\n      3. Interactive: Polls, quizzes, contests\\n\\nVI. Frequency of Posts:\\n   A. Facebook: 1-2 times per day\\n   B. Instagram: 1-3 times per day\\n   C. Twitter: 5-7 times per day\\n   D. LinkedIn: 1-2 times per day\\n   E. YouTube: 1-2 times per week\\n   F. Pinterest: 1-3 times per day (if applicable)\\n\\nVII. Metrics for Measuring Success:\\n   A. Engagement metrics: Likes, comments, shares, retweets, mentions\\n   B. Community growth metrics: New followers, page likes, group members\\n   C. Traffic metrics: Clicks, website visitors, bounce rate, time on site\\n   D. Conversion metrics: Leads generated, sales, newsletter sign-ups\\n\\nVIII. Timeline for Implementation:\\n   A. Weeks 1-4: Platform set-up, content development, initial promotion\\n   B. Weeks 5-12: Community growth, engagement building, on-going content creation\\n   C. Weeks 13-26: Data analysis, optimization, expansion to new channels (if applicable)\\n\\nIX. Budget Allocation for Paid Social Media Advertising:\\n   A. Initial allocation: 50% of total marketing budget \\n   B. Monthly reallocation based on performance data and optimization efforts\\n\\nRemember, this is a sample plan, and all areas can be tailored to better suit the specific needs of your initiative. Remember to continually analyze metrics, optimize your tactics, and adjust the plan as needed to maximize success.', 'role': 'assistant'}], 'rejected': [{'content': 'Create a comprehensive social media plan that outlines the objectives, target audience, platforms, messaging, content strategy, tone of voice, frequency of posts, and metrics for measuring success for a new initiative. The plan should also include a timeline for implementation and a budget allocation for paid social media advertising.', 'role': 'user'}, {'content': \"Of course, I'd be happy to help you with that! Here's a comprehensive social media plan for a new initiative:\\nObjectives:\\n* Raise awareness about the initiative and its goals\\n* Build engagement and community around the initiative\\n* Drive website traffic and increase conversions\\n* Improve brand visibility and credibility\\n\\nTarget Audience:\\n\\n* Demographic: Generate a detailed profile of the target audience for the initiative, including their age, gender, interests, behaviors, and pain points.\\n* Psychographic: Identify the attitudes, values, and lifestyle of the target audience.\\n\\nPlatforms:\\n\\n* Define the social media platforms where the initiative will be active, such as Facebook, Instagram, Twitter, LinkedIn, and YouTube.\\n\\nMessaging:\\n\\n* Craft clear, concise, and compelling messages that resonate with the target audience and align with the objectives of the initiative.\\n* Develop key messages that highlight the benefits of the initiative and why it's important to the target audience.\\n\\nContent Strategy:\\n\\n* Define the types of content that will be created and shared, such as blog posts, videos, infographics, and case studies.\\n* Identify the topics and themes that will be covered, such as industry trends, thought leadership, and success stories.\\n\\nTone of Voice:\\n\\n* Establish a consistent tone of voice that reflects the personality and values of the initiative.\\n* Define the language and terminology that will be used to communicate with the target audience.\\n\\nFrequency of Posts:\\n\\n* Outline the number of posts that will be created and shared per week or per month.\\n* Define the content calendar, including the topics, formats, and timelines for each post.\\n\\nMetrics for Measuring Success:\\n\\n* Define the metrics that will be used to measure the success of the initiative, such as website traffic, engagement, conversions, and brand visibility.\\n* Identify the tools and platforms that will be used to track and monitor these metrics.\\n\\nImplementation Timeline:\\n\\n* Outline the timeline for implementing the social media plan, including the expected start and end dates for each phase.\\n* Identify the resources and budget that will be required to execute the plan.\\n\\nBudget Allocation for Paid Social Media Advertising:\\n\\n* Determine the budget allocation for paid social media advertising, including the platforms, ad formats, and target audiences.\\n* Define the goals and objectives for each paid social media campaign, and the metrics that will be used to measure success.\\n\\nBy following this comprehensive social media plan, the initiative is expected to increase brand visibility, engagement, and conversions, while also improving the overall effectiveness of the initiative.\", 'role': 'assistant'}], 'score_chosen': 8.5, 'score_rejected': 8.5}\n",
            "\n",
            "=== Training Time ===\n",
            "66.78 seconds\n",
            "\n",
            "\n",
            "=== Evaluation Metrics ===\n",
            "rouge1: 0.1440\n",
            "rouge2: 0.0401\n",
            "rougeL: 0.0997\n",
            "generation_time: 91.1412\n",
            "tokens_per_second: 21.3734\n",
            "training_time: 66.7764\n",
            "\n",
            "=== Sample Generated Outputs ===\n",
            "\n",
            "Sample 1:\n",
            "Prompt: Create a comprehensive social media plan that outlines the objectives, target audience, platforms, messaging, content strategy, tone of voice, frequency of posts, and metrics for measuring success for a new initiative. The plan should also include a timeline for implementation and a budget allocation for paid social media advertising.\n",
            "Reference: Title: Comprehensive Social Media Plan for a New Initiative\n",
            "\n",
            "I. Objectives:\n",
            "   A. Increase brand awareness and visibility\n",
            "   B. Generate a loyal and engaged community\n",
            "   C. Drive traffic to the website\n",
            "   D. Generate leads and sales\n",
            "   E. Establish ourselves as thought leaders in the industry\n",
            "\n",
            "II. Target Audience:\n",
            "   A. Demographics\n",
            "      1. Age group: 24-45\n",
            "      2. Gender: Male and female\n",
            "      3. Location: United States\n",
            "      4. Occupation: Professionals and entrepreneurs\n",
            "   B. Psychographics\n",
            "      1. Interests: Technology, innovation, self-improvement, business growth\n",
            "      2. Values: Success, progress, creativity, collaboration\n",
            "\n",
            "III. Platforms:\n",
            "   A. Facebook\n",
            "   B. Instagram\n",
            "   C. Twitter\n",
            "   D. LinkedIn\n",
            "   E. YouTube\n",
            "   F. Pinterest (optional, depending on the content and industry)\n",
            "\n",
            "IV. Messaging:\n",
            "   A. Key messages\n",
            "      1. Our product/service helps you achieve success\n",
            "      2. Join a community of like-minded individuals\n",
            "      3. Stay ahead of the curve with the latest industry news and insights\n",
            "   B. Tone of voice: Informative, engaging, and inspirational\n",
            "\n",
            "V. Content Strategy:\n",
            "   A. Content pillars\n",
            "      1. Educational (e.g., how-to guides, industry trends)\n",
            "      2. Engaging (e.g., interactive polls, user-generated content)\n",
            "      3. Promotional (e.g., product updates, discounts, sales)\n",
            "   B. Content formats\n",
            "      1. Visual: Images, infographics, videos\n",
            "      2. Written: Blog articles, social media posts, interviews, case studies\n",
            "      3. Interactive: Polls, quizzes, contests\n",
            "\n",
            "VI. Frequency of Posts:\n",
            "   A. Facebook: 1-2 times per day\n",
            "   B. Instagram: 1-3 times per day\n",
            "   C. Twitter: 5-7 times per day\n",
            "   D. LinkedIn: 1-2 times per day\n",
            "   E. YouTube: 1-2 times per week\n",
            "   F. Pinterest: 1-3 times per day (if applicable)\n",
            "\n",
            "VII. Metrics for Measuring Success:\n",
            "   A. Engagement metrics: Likes, comments, shares, retweets, mentions\n",
            "   B. Community growth metrics: New followers, page likes, group members\n",
            "   C. Traffic metrics: Clicks, website visitors, bounce rate, time on site\n",
            "   D. Conversion metrics: Leads generated, sales, newsletter sign-ups\n",
            "\n",
            "VIII. Timeline for Implementation:\n",
            "   A. Weeks 1-4: Platform set-up, content development, initial promotion\n",
            "   B. Weeks 5-12: Community growth, engagement building, on-going content creation\n",
            "   C. Weeks 13-26: Data analysis, optimization, expansion to new channels (if applicable)\n",
            "\n",
            "IX. Budget Allocation for Paid Social Media Advertising:\n",
            "   A. Initial allocation: 50% of total marketing budget \n",
            "   B. Monthly reallocation based on performance data and optimization efforts\n",
            "\n",
            "Remember, this is a sample plan, and all areas can be tailored to better suit the specific needs of your initiative. Remember to continually analyze metrics, optimize your tactics, and adjust the plan as needed to maximize success.\n",
            "Model Output: To create a comprehensive social media platform, you would need to focus on your target audience and understand how they are connected with your brand. Here's a sample social media plan to make a significant impact in your business:\n",
            "Objective: Create a significant impact in\n",
            "\n",
            "Sample 2:\n",
            "Prompt: Please give me 50 topics for my health coach social media posts.copycopy\n",
            "Reference: Of course! As a helpful and respectful assistant, I'm happy to provide you with 50 topics for your health coach social media posts that are socially unbiased, positive, and informative. Here are 50 ideas to get you started:\n",
            "\n",
            "1. Mindful eating tips for a healthier lifestyle\n",
            "2. Benefits of meditation and mindfulness practices\n",
            "3. Simple exercises to improve flexibility and mobility\n",
            "4. How to boost your immune system naturally\n",
            "5. Easy meal prep ideas for busy days\n",
            "6. Tips for getting enough sleep and improving sleep quality\n",
            "7. Healthy snack ideas for on-the-go\n",
            "8. The importance of stretching and how to incorporate it into your daily routine\n",
            "9. Affordable self-care practices for a healthy lifestyle\n",
            "10. Quick and easy workout routines for beginners\n",
            "11. The benefits of a plant-based diet and how to incorporate more plants into your meals\n",
            "12. How to stay hydrated and why it's important for overall health\n",
            "13. Tips for managing stress and anxiety naturally\n",
            "14. Exploring the benefits of different types of exercise, such as weightlifting, yoga, or running\n",
            "15. How to connect with your body and listen to its needs\n",
            "16. Self-care for the mind and body\n",
            "17. The importance of maintaining a healthy gut and how to do it\n",
            "18. Tips for cooking healthy meals and making healthy snacks\n",
            "19. Understanding the benefits of supplements and when they may be necessary\n",
            "20. How to set achievable and sustainable health goals\n",
            "21. Exploring the benefits of different types of tea and their health benefits\n",
            "22. Tips for freeing up space in your home and decluttering your life\n",
            "23. Easy and healthy meal ideas for families on a budget\n",
            "24. How to boost your mood and energy levels naturally\n",
            "25. The importance of taking breaks and self-care for parents and caregivers\n",
            "26. How to set realistic and achievable health goals\n",
            "27. The benefits of aromatherapy and how to incorporate it into your self-care routine\n",
            "28. Tips for improving digestion and reducing bloating\n",
            "29. How to prioritize your health and well-being in a busy schedule\n",
            "30. The benefits of taking a digital detox and how to do it safely\n",
            "31. How to deal with sore muscles and joints after exercise\n",
            "32. Understanding the benefits of probiotics and how to incorporate them into your diet\n",
            "33. Tips for reducing stress in the workplace\n",
            "34. The benefits of forest bathing and how to incorporate it into your self-care routine\n",
            "35. How to make healthy choices when eating out or ordering takeout\n",
            "36. The importance of practicing self-compassion and self-love\n",
            "37. How to stay active and healthy while traveling\n",
            "38. Tips for improving your posture and reducing back pain\n",
            "39. The benefits of reading and how it can improve your mental and emotional health\n",
            "40. How to incorporate more movement into your daily routine\n",
            "41. The benefits of a healthy gut and how to keep it healthy\n",
            "42. Tips for dealing with headaches and migraines naturally\n",
            "43. The importance of rest and recovery for overall health and well-being\n",
            "44. How to reduce the risk of chronic diseases and improve your overall health\n",
            "45. Tips for staying healthy and happy while working from home\n",
            "46. The benefits of nature and how it can improve your mental and emotional health\n",
            "47. How to incorporate more mindfulness into your daily routine\n",
            "48. The benefits of yoga and meditation for mental and physical health\n",
            "49. Tips for improving your immune system naturally\n",
            "50. The importance of prioritizing your mental health and well-being\n",
            "\n",
            "I hope these topics help inspire you for your health coach social media posts! Remember to always provide helpful, safe, and positive information that is socially unbiased and respectful.\n",
            "Model Output: to your social media platforms and other relevant platforms. The goal is not just to create a successful health coaching business, but rather to create a successful and effective social media platform that allows you to connect with clients, build relationships, and foster relationships with clients\n",
            "\n",
            "Sample 3:\n",
            "Prompt: TALLAHASSEE, Fla. – The National Collegiate Athletic Association (NCAA) Division I Committee on Athletics Certification has certified Florida A&M University (FAMU) and 34 other Division I member institutions that have undergone the Association’s second cycle of athletics certification.\n",
            "The purpose of athletics certification is to ensure integrity in the institution’s athletics program and to assist institutions in improving their athletics departments. NCAA legislation mandating athletics certification was adopted in 1993.\n",
            "The certification process, which involves a self-study led by an institution’s president or chancellor, includes a review of these primary components: governance and commitment to rules compliance; academic integrity; equity; and student-athlete well-being.\n",
            "A designation of “certified” means that an institution operates its athletics program in substantial conformity with operating principles adopted by the Division I membership.\n",
            "This classification means that the institution is considered to be operating its athletics program in substantial conformity with operating principles adopted by the NCAA's Division I membership. However, problems identified during the course of the institution's self-study and the peer-review team's evaluation were considered serious enough by the Committee on Athletics Certification to cause it to withhold full certification until those problems have been corrected. The NCAA does not divulge specific information related to an institution’s self-study or peer-review visit or specific information concerning the conditions set forth for certification.\n",
            "The second round of athletics certifications is being completed on a 10-year cycle rather than the five-year cycle used during the initial certification process. All 326 active Division I members participate in the certification process.\n",
            "The Division I Committee on Athletics Certification preliminarily reviews an institution’s certification materials and provides a list of issues identified during the evaluation. The university then hosts a visit by peer reviewers who file a report regarding the institution’s resolution of those issues before a final certification decision is rendered. An institution’s failure to satisfactorily respond to the committee may negatively impact certification status.\n",
            "The members of the committee on Athletics Certification are: Robert Bernardi, Nicholls State University; McKinley Boston Jr., New Mexico State University; Wheeler Brown, North Carolina A&T State University; Rita Hartung Cheng, University of Wisconsin, Milwaukee; Casey Comoroski, Missouri State University; Beatrice Crane Banford, Marshall University; Amy Folan, University of Texas at Austin; Judy Genshaft, University of South Florida; Joanne Glasser, Bradley University; Nathan Hatch (chair), Wake Forest University; Brian Linnane, Loyola College (Maryland); M. Dianne Murphy, Columbia University-Barnard College; Gloria Nevarez, University of Oklahoma; Sheila Patterson, Cleveland State University; Donald Pope-Davis, University of Notre Dame; Allison Rich, California State University, Fullerton; Christopher Ritrievi, University of Utah; and Jon Steinbrecher, Ohio Valley Conference. Can an institution receive full certification if there are problems identified during the certification process?\n",
            "Reference: Yes, an institution can receive full certification even if problems are identified during the certification process. However, the institution must address these issues and provide evidence of corrective action taken before full certification can be granted. The purpose of athletics certification is to ensure that institutions are operating their athletics programs in a manner consistent with NCAA rules and principles, and the committee recognizes that correcting issues identified during the certification process is essential to achieving this goal.\n",
            "Model Output: The answer to an institution receiving full certification under the first cycle of athletics certification would be to resolve the issues identified during the process and address them. This could involve adjustments to the institution’s structure, personnel, or practices. The committee will review the results\n",
            "\n",
            "Sample 4:\n",
            "Prompt: please create a schume of the 20 tabels , do not miss any of the 20 tabels\n",
            "Reference: As an AI assistant, my aim is to always be transparent and provide accurate information. I apologize, but I don't understand what \"create a schume of the 20 tables\" means. Could you please provide more context or clarify your request? I would be happy to try and assist you further.\n",
            "Model Output: and make sure they are distinct. To create a unique schume (schume is the process of organizing and analyzing data, it aims to create a new dataset that you have never seen before. Here's a schume to help you understand how each\n",
            "\n",
            "Sample 5:\n",
            "Prompt: def verify\\_password(\n",
            " hash: bytes, password: bytes, type: Type = Type.I\n",
            ") -> Literal[True]:\n",
            " \"\"\"\n",
            " Legacy alias for :func:`verify\\_secret` with default parameters.\n",
            "\n",
            " .. deprecated:: 16.0.0\n",
            " Use :class:`argon2.PasswordHasher` for passwords.\n",
            " \"\"\"\n",
            " return verify\\_secret(hash, password, type)\n",
            "Reference: This function, `verify_password`, checks if a given password matches the hashed version of that password. This is typically used for user authentication purposes. It is, however, marked as deprecated in version 16.0.0, which means that it is outdated and not recommended for use in new projects. The `argon2.PasswordHasher` class is recommended for password hashing and verification in newer implementations.\n",
            "\n",
            "Here's a breakdown of the `verify_password` function parameters:\n",
            "\n",
            "- `hash: bytes` - The hashed version of the password.\n",
            "- `password: bytes` - The password to be verified.\n",
            "- `type: Type` *(optional)* - An optional type parameter with a default value of `Type.I`.\n",
            "\n",
            "The function returns a literal `True` if the password matches the hash; otherwise, it raises an exception.\n",
            "\n",
            "To use the recommended `argon2.PasswordHasher` class in a new project, follow these steps:\n",
            "\n",
            "1. Install the `argon2-cffi` library:\n",
            "\n",
            "```bash\n",
            "pip install argon2-cffi\n",
            "```\n",
            "\n",
            "2. Use the `argon2.PasswordHasher` class to hash and verify passwords:\n",
            "\n",
            "```python\n",
            "from argon2 import PasswordHasher\n",
            "\n",
            "# Create a PasswordHasher instance\n",
            "ph = PasswordHasher()\n",
            "\n",
            "# Hash a password\n",
            "password = \"example_password\"\n",
            "hashed = ph.hash(password)\n",
            "\n",
            "# Verify a password\n",
            "try:\n",
            "    ph.verify(hashed, password)\n",
            "    print(\"Password is correct.\")\n",
            "except:\n",
            "    print(\"Incorrect password.\")\n",
            "```\n",
            "\n",
            "Using `argon2.PasswordHasher` provides a more secure and up-to-date method for handling password hashing and verification in your projects.\n",
            "Model Output: == expected_hash\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    hash = input(\"Enter the hash to be used: \")\n",
            "    password = input(\"Enter the password to be used: \")\n",
            "    type = input(\"Enter the type of hashing to be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1wpotC-llcbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics, results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDBOVgcHqxVs",
        "outputId": "953cd009-ba7c-4170-abac-d64e97ec19af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 0.14401077881391675, 'rouge2': 0.04014290703139522, 'rougeL': 0.09967850593229491, 'generation_time': 91.14116072654724, 'tokens_per_second': 21.373438570138752, 'training_time': 66.77635622024536} {'method': 'DPO', 'evaluation_metrics': {'rouge1': 0.14401077881391675, 'rouge2': 0.04014290703139522, 'rougeL': 0.09967850593229491, 'generation_time': 91.14116072654724, 'tokens_per_second': 21.373438570138752, 'training_time': 66.77635622024536}, 'samples': [{'prompt': 'Create a comprehensive social media plan that outlines the objectives, target audience, platforms, messaging, content strategy, tone of voice, frequency of posts, and metrics for measuring success for a new initiative. The plan should also include a timeline for implementation and a budget allocation for paid social media advertising.', 'generation': \"To create a comprehensive social media platform, you would need to focus on your target audience and understand how they are connected with your brand. Here's a sample social media plan to make a significant impact in your business:\\nObjective: Create a significant impact in\", 'reference': 'Title: Comprehensive Social Media Plan for a New Initiative\\n\\nI. Objectives:\\n   A. Increase brand awareness and visibility\\n   B. Generate a loyal and engaged community\\n   C. Drive traffic to the website\\n   D. Generate leads and sales\\n   E. Establish ourselves as thought leaders in the industry\\n\\nII. Target Audience:\\n   A. Demographics\\n      1. Age group: 24-45\\n      2. Gender: Male and female\\n      3. Location: United States\\n      4. Occupation: Professionals and entrepreneurs\\n   B. Psychographics\\n      1. Interests: Technology, innovation, self-improvement, business growth\\n      2. Values: Success, progress, creativity, collaboration\\n\\nIII. Platforms:\\n   A. Facebook\\n   B. Instagram\\n   C. Twitter\\n   D. LinkedIn\\n   E. YouTube\\n   F. Pinterest (optional, depending on the content and industry)\\n\\nIV. Messaging:\\n   A. Key messages\\n      1. Our product/service helps you achieve success\\n      2. Join a community of like-minded individuals\\n      3. Stay ahead of the curve with the latest industry news and insights\\n   B. Tone of voice: Informative, engaging, and inspirational\\n\\nV. Content Strategy:\\n   A. Content pillars\\n      1. Educational (e.g., how-to guides, industry trends)\\n      2. Engaging (e.g., interactive polls, user-generated content)\\n      3. Promotional (e.g., product updates, discounts, sales)\\n   B. Content formats\\n      1. Visual: Images, infographics, videos\\n      2. Written: Blog articles, social media posts, interviews, case studies\\n      3. Interactive: Polls, quizzes, contests\\n\\nVI. Frequency of Posts:\\n   A. Facebook: 1-2 times per day\\n   B. Instagram: 1-3 times per day\\n   C. Twitter: 5-7 times per day\\n   D. LinkedIn: 1-2 times per day\\n   E. YouTube: 1-2 times per week\\n   F. Pinterest: 1-3 times per day (if applicable)\\n\\nVII. Metrics for Measuring Success:\\n   A. Engagement metrics: Likes, comments, shares, retweets, mentions\\n   B. Community growth metrics: New followers, page likes, group members\\n   C. Traffic metrics: Clicks, website visitors, bounce rate, time on site\\n   D. Conversion metrics: Leads generated, sales, newsletter sign-ups\\n\\nVIII. Timeline for Implementation:\\n   A. Weeks 1-4: Platform set-up, content development, initial promotion\\n   B. Weeks 5-12: Community growth, engagement building, on-going content creation\\n   C. Weeks 13-26: Data analysis, optimization, expansion to new channels (if applicable)\\n\\nIX. Budget Allocation for Paid Social Media Advertising:\\n   A. Initial allocation: 50% of total marketing budget \\n   B. Monthly reallocation based on performance data and optimization efforts\\n\\nRemember, this is a sample plan, and all areas can be tailored to better suit the specific needs of your initiative. Remember to continually analyze metrics, optimize your tactics, and adjust the plan as needed to maximize success.'}, {'prompt': 'Please give me 50 topics for my health coach social media posts.copycopy', 'generation': 'to your social media platforms and other relevant platforms. The goal is not just to create a successful health coaching business, but rather to create a successful and effective social media platform that allows you to connect with clients, build relationships, and foster relationships with clients', 'reference': \"Of course! As a helpful and respectful assistant, I'm happy to provide you with 50 topics for your health coach social media posts that are socially unbiased, positive, and informative. Here are 50 ideas to get you started:\\n\\n1. Mindful eating tips for a healthier lifestyle\\n2. Benefits of meditation and mindfulness practices\\n3. Simple exercises to improve flexibility and mobility\\n4. How to boost your immune system naturally\\n5. Easy meal prep ideas for busy days\\n6. Tips for getting enough sleep and improving sleep quality\\n7. Healthy snack ideas for on-the-go\\n8. The importance of stretching and how to incorporate it into your daily routine\\n9. Affordable self-care practices for a healthy lifestyle\\n10. Quick and easy workout routines for beginners\\n11. The benefits of a plant-based diet and how to incorporate more plants into your meals\\n12. How to stay hydrated and why it's important for overall health\\n13. Tips for managing stress and anxiety naturally\\n14. Exploring the benefits of different types of exercise, such as weightlifting, yoga, or running\\n15. How to connect with your body and listen to its needs\\n16. Self-care for the mind and body\\n17. The importance of maintaining a healthy gut and how to do it\\n18. Tips for cooking healthy meals and making healthy snacks\\n19. Understanding the benefits of supplements and when they may be necessary\\n20. How to set achievable and sustainable health goals\\n21. Exploring the benefits of different types of tea and their health benefits\\n22. Tips for freeing up space in your home and decluttering your life\\n23. Easy and healthy meal ideas for families on a budget\\n24. How to boost your mood and energy levels naturally\\n25. The importance of taking breaks and self-care for parents and caregivers\\n26. How to set realistic and achievable health goals\\n27. The benefits of aromatherapy and how to incorporate it into your self-care routine\\n28. Tips for improving digestion and reducing bloating\\n29. How to prioritize your health and well-being in a busy schedule\\n30. The benefits of taking a digital detox and how to do it safely\\n31. How to deal with sore muscles and joints after exercise\\n32. Understanding the benefits of probiotics and how to incorporate them into your diet\\n33. Tips for reducing stress in the workplace\\n34. The benefits of forest bathing and how to incorporate it into your self-care routine\\n35. How to make healthy choices when eating out or ordering takeout\\n36. The importance of practicing self-compassion and self-love\\n37. How to stay active and healthy while traveling\\n38. Tips for improving your posture and reducing back pain\\n39. The benefits of reading and how it can improve your mental and emotional health\\n40. How to incorporate more movement into your daily routine\\n41. The benefits of a healthy gut and how to keep it healthy\\n42. Tips for dealing with headaches and migraines naturally\\n43. The importance of rest and recovery for overall health and well-being\\n44. How to reduce the risk of chronic diseases and improve your overall health\\n45. Tips for staying healthy and happy while working from home\\n46. The benefits of nature and how it can improve your mental and emotional health\\n47. How to incorporate more mindfulness into your daily routine\\n48. The benefits of yoga and meditation for mental and physical health\\n49. Tips for improving your immune system naturally\\n50. The importance of prioritizing your mental health and well-being\\n\\nI hope these topics help inspire you for your health coach social media posts! Remember to always provide helpful, safe, and positive information that is socially unbiased and respectful.\"}, {'prompt': \"TALLAHASSEE, Fla. – The National Collegiate Athletic Association (NCAA) Division I Committee on Athletics Certification has certified Florida A&M University (FAMU) and 34 other Division I member institutions that have undergone the Association’s second cycle of athletics certification.\\nThe purpose of athletics certification is to ensure integrity in the institution’s athletics program and to assist institutions in improving their athletics departments. NCAA legislation mandating athletics certification was adopted in 1993.\\nThe certification process, which involves a self-study led by an institution’s president or chancellor, includes a review of these primary components: governance and commitment to rules compliance; academic integrity; equity; and student-athlete well-being.\\nA designation of “certified” means that an institution operates its athletics program in substantial conformity with operating principles adopted by the Division I membership.\\nThis classification means that the institution is considered to be operating its athletics program in substantial conformity with operating principles adopted by the NCAA's Division I membership. However, problems identified during the course of the institution's self-study and the peer-review team's evaluation were considered serious enough by the Committee on Athletics Certification to cause it to withhold full certification until those problems have been corrected. The NCAA does not divulge specific information related to an institution’s self-study or peer-review visit or specific information concerning the conditions set forth for certification.\\nThe second round of athletics certifications is being completed on a 10-year cycle rather than the five-year cycle used during the initial certification process. All 326 active Division I members participate in the certification process.\\nThe Division I Committee on Athletics Certification preliminarily reviews an institution’s certification materials and provides a list of issues identified during the evaluation. The university then hosts a visit by peer reviewers who file a report regarding the institution’s resolution of those issues before a final certification decision is rendered. An institution’s failure to satisfactorily respond to the committee may negatively impact certification status.\\nThe members of the committee on Athletics Certification are: Robert Bernardi, Nicholls State University; McKinley Boston Jr., New Mexico State University; Wheeler Brown, North Carolina A&T State University; Rita Hartung Cheng, University of Wisconsin, Milwaukee; Casey Comoroski, Missouri State University; Beatrice Crane Banford, Marshall University; Amy Folan, University of Texas at Austin; Judy Genshaft, University of South Florida; Joanne Glasser, Bradley University; Nathan Hatch (chair), Wake Forest University; Brian Linnane, Loyola College (Maryland); M. Dianne Murphy, Columbia University-Barnard College; Gloria Nevarez, University of Oklahoma; Sheila Patterson, Cleveland State University; Donald Pope-Davis, University of Notre Dame; Allison Rich, California State University, Fullerton; Christopher Ritrievi, University of Utah; and Jon Steinbrecher, Ohio Valley Conference. Can an institution receive full certification if there are problems identified during the certification process?\", 'generation': 'The answer to an institution receiving full certification under the first cycle of athletics certification would be to resolve the issues identified during the process and address them. This could involve adjustments to the institution’s structure, personnel, or practices. The committee will review the results', 'reference': 'Yes, an institution can receive full certification even if problems are identified during the certification process. However, the institution must address these issues and provide evidence of corrective action taken before full certification can be granted. The purpose of athletics certification is to ensure that institutions are operating their athletics programs in a manner consistent with NCAA rules and principles, and the committee recognizes that correcting issues identified during the certification process is essential to achieving this goal.'}, {'prompt': 'please create a schume of the 20 tabels , do not miss any of the 20 tabels', 'generation': \"and make sure they are distinct. To create a unique schume (schume is the process of organizing and analyzing data, it aims to create a new dataset that you have never seen before. Here's a schume to help you understand how each\", 'reference': 'As an AI assistant, my aim is to always be transparent and provide accurate information. I apologize, but I don\\'t understand what \"create a schume of the 20 tables\" means. Could you please provide more context or clarify your request? I would be happy to try and assist you further.'}, {'prompt': 'def verify\\\\_password(\\n hash: bytes, password: bytes, type: Type = Type.I\\n) -> Literal[True]:\\n \"\"\"\\n Legacy alias for :func:`verify\\\\_secret` with default parameters.\\n\\n .. deprecated:: 16.0.0\\n Use :class:`argon2.PasswordHasher` for passwords.\\n \"\"\"\\n return verify\\\\_secret(hash, password, type)', 'generation': '== expected_hash\\n\\nif __name__ == \\'__main__\\':\\n    hash = input(\"Enter the hash to be used: \")\\n    password = input(\"Enter the password to be used: \")\\n    type = input(\"Enter the type of hashing to be', 'reference': 'This function, `verify_password`, checks if a given password matches the hashed version of that password. This is typically used for user authentication purposes. It is, however, marked as deprecated in version 16.0.0, which means that it is outdated and not recommended for use in new projects. The `argon2.PasswordHasher` class is recommended for password hashing and verification in newer implementations.\\n\\nHere\\'s a breakdown of the `verify_password` function parameters:\\n\\n- `hash: bytes` - The hashed version of the password.\\n- `password: bytes` - The password to be verified.\\n- `type: Type` *(optional)* - An optional type parameter with a default value of `Type.I`.\\n\\nThe function returns a literal `True` if the password matches the hash; otherwise, it raises an exception.\\n\\nTo use the recommended `argon2.PasswordHasher` class in a new project, follow these steps:\\n\\n1. Install the `argon2-cffi` library:\\n\\n```bash\\npip install argon2-cffi\\n```\\n\\n2. Use the `argon2.PasswordHasher` class to hash and verify passwords:\\n\\n```python\\nfrom argon2 import PasswordHasher\\n\\n# Create a PasswordHasher instance\\nph = PasswordHasher()\\n\\n# Hash a password\\npassword = \"example_password\"\\nhashed = ph.hash(password)\\n\\n# Verify a password\\ntry:\\n    ph.verify(hashed, password)\\n    print(\"Password is correct.\")\\nexcept:\\n    print(\"Incorrect password.\")\\n```\\n\\nUsing `argon2.PasswordHasher` provides a more secure and up-to-date method for handling password hashing and verification in your projects.'}], 'training_time': 66.77635622024536, 'model_size': 494032768, 'parameters': {'beta': 1.0, 'learning_rate': 0.0001, 'batch_size': 1, 'epochs': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOb_ODHdByDq",
        "outputId": "759e9b9d-4306-4b60-cde0-2e53638a59d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.7.2)\n",
            "Collecting trl\n",
            "  Using cached trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.3.0)\n",
            "Collecting datasets>=2.21.0 (from trl)\n",
            "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.48.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl) (3.11.13)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Using cached trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "Installing collected packages: datasets, trl\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.5\n",
            "    Uninstalling datasets-2.14.5:\n",
            "      Successfully uninstalled datasets-2.14.5\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.7.2\n",
            "    Uninstalling trl-0.7.2:\n",
            "      Successfully uninstalled trl-0.7.2\n",
            "Successfully installed datasets-3.3.2 trl-0.15.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "trl"
                ]
              },
              "id": "23921bb9991c40928afb15082ba389f2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpCd8cL_ChL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}